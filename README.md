# Optimizing an ML Pipeline in Azure

# Overview

This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

# Summary

### **Problem Statement**

The dataset describes about the marketing campagins for a bank, which consists of the information about :-

- Bank client data (**attributes** :- age, job, marital, education, default, housing, loan, balance)
- The last contact of the current campaign (**attributes** :- contact, month, day, duration)
- Other (**attributes** :- campaign, Pdays, previous, poutcome)
  - **y** is the desired target, where we need to know whether client subscribed the term deposit or not (**yes** or **no**) . The dataset contains 32950 training data in CSV file and its a classification problem.

### **Solution for the problem statement**

![Optimizing_ML_Pipeline](azure_pipeline.png)
The above figure describes how to perform the problem statement in an effective way, there are two ways of approaching the problem:-

- To optimize the hyper parameter of custom coded model using a tool called **HyperDrive**. HyperDrive will help us to find the best parameter to the model compared to manual Hyperparameter tuning.
- **AutoML** which helps us to choose the best algorithm, which evaluates the different pipelines on its own and help us to find the best optimal solution in a faster way.

# Scikit-learn Pipeline

### Pipeline architecture including data, HyperParameter tuning and classification algorithm.

### Benefits of the parameter sampler.

### Benefits of the early stopping policy.

- train.python scripts performs several operations they are listed as follows :-
  - It consists of import statements to load the libraries which we need to process in the experiment.
  - Need to import the CSV file which contains the marketing campaigns data into a TabularDataFactory method.
  - Cleans the data in clean_data() function method.
  - clean_data() function includes handling missing values, dropping NaN values and also dropped irrelevant columns which is not needed for the experiment, one hot encoding for categorical features, loads data into pandas dataframe.
  - Splitting dataset into training and testing set(80% training, 20% testing)
  - .fit method applies the logistic regression to the model and computes the accuracy score for the model.Files are saved in "./outputs/".

#### To use HyperDrive to tune HyperParameter

- **Select a sampling method** :- **RandomParameter Sampling** is used to randomly select a value for each hyperparameter, which can be a mix of discrete and continuous values.Here in code we need to search for parameter like "\__C" and "_ \_max_iter"
- **PrimaryMetric Goal** :- It is used to determine whether a higher value for a metric is better or worse. In this experiment primary metric is **accuracy**.We can maximize or minimize for betterment of model.
-

### Algorithm

- Logistic Regression is a binary classification algorithm in which dependent variable is binary i,e
  1(True,Sucess),0(False,Failure). Goal is to find the best fitting model for independent and dependent variable in the relationship. Independent variable can be continous or binary, also called as **logit regression**, used in machine learning,deals with probability to measure the relation between dependent and independent variables.

# AutoML

**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison

**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work

**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up

**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
